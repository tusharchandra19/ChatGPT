# ChatGPT

Built a Generatively Pretrained Transformer (GPT), following the paper "Attention is All You Need" and OpenAI's GPT-2 / GPT-3. ChatGPT has taken the world by storm so tried writing a nano version of it that works on a small excerpt of 1.1 million characters taken from Shakespeare's play which is included in the folder itself. Also, tried bigram model which can be seen in practice code. 
